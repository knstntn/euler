{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from summa import keywords\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 1000\n",
    "n_top_words = 2\n",
    "n_components = 5\n",
    "\n",
    "def read_text(url):\n",
    "    txt = requests.get(url).text\n",
    "    return [x.strip() for x in txt.split('\\r\\n') if x.strip() != '']\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "\n",
    "def print_most_frequent(vec, bag_of_words):\n",
    "    sum_words = bag_of_words .sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    print(words_freq[:n_components])\n",
    "    print()\n",
    "\n",
    "def get_tf_idf_data(txt, ngram_range=(1,1), print_frequencies=False):\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=0.95, \n",
    "                                       min_df=2,\n",
    "                                       ngram_range=ngram_range,\n",
    "                                       max_features=n_features, \n",
    "                                       stop_words='english')\n",
    "    tfidf = tfidf_vectorizer.fit_transform(txt)\n",
    "    \n",
    "    if print_frequencies:\n",
    "        print_most_frequent(tfidf_vectorizer, tfidf)\n",
    "    \n",
    "    return (tfidf_vectorizer, tfidf)\n",
    "    \n",
    "def get_tf_data(txt, ngram_range=(1,1), print_frequencies=False):\n",
    "    tf_vectorizer = CountVectorizer(max_df=0.95, \n",
    "                                    min_df=2,\n",
    "                                    ngram_range=ngram_range,\n",
    "                                    max_features=n_features,\n",
    "                                    stop_words='english')\n",
    "    tf = tf_vectorizer.fit_transform(txt)\n",
    "    \n",
    "    if print_frequencies:\n",
    "        print_most_frequent(tf_vectorizer, tf)\n",
    "    \n",
    "    return (tf_vectorizer, tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "txt = read_text(\"http://www.glozman.com/TextPages/Harry%20Potter%201%20-%20Sorcerer's%20Stone.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('said harry', 143), ('said ron', 111), ('uncle vernon', 108), ('professor mcgonagall', 95), ('said hagrid', 89)]\n",
      "\n",
      "CPU times: user 192 ms, sys: 122 µs, total: 192 ms\n",
      "Wall time: 442 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = get_tf_data(txt, (2,2), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('said harry', 87.16511421562596), ('said ron', 59.78064567759409), ('uncle vernon', 57.043435884277244), ('said hagrid', 51.44077989128559), ('professor mcgonagall', 49.124548569059336)]\n",
      "\n",
      "CPU times: user 191 ms, sys: 18 µs, total: 191 ms\n",
      "Wall time: 487 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = get_tf_idf_data(txt, (2,2), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Negative Matrix Factorization and Frobenius norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: said dumbledore\n",
      "Topic #1: harry potter\n",
      "Topic #2: ron hermione\n",
      "Topic #3: hagrid looked\n",
      "Topic #4: don know\n",
      "\n",
      "CPU times: user 174 ms, sys: 1.21 ms, total: 175 ms\n",
      "Wall time: 405 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "(tf_idf_vectorizer, tfidf) = get_tf_idf_data(txt)\n",
    "nmf = NMF(n_components=n_components, alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "print_top_words(nmf, tf_idf_vectorizer.get_feature_names(), n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Negative Matrix Factorization and Kullback-Leibler divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: said harry\n",
      "Topic #1: harry vernon\n",
      "Topic #2: ron hermione\n",
      "Topic #3: hagrid looked\n",
      "Topic #4: know professor\n",
      "\n",
      "CPU times: user 536 ms, sys: 379 µs, total: 536 ms\n",
      "Wall time: 1.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "(tf_idf_vectorizer, tfidf) = get_tf_idf_data(txt)\n",
    "nmf = NMF(n_components=n_components, \n",
    "          beta_loss='kullback-leibler', \n",
    "          solver='mu', \n",
    "          max_iter=1000, \n",
    "          alpha=.1,\n",
    "          l1_ratio=.5).fit(tfidf)\n",
    "print_top_words(nmf, tf_idf_vectorizer.get_feature_names(), n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: said know\n",
      "Topic #1: harry uncle\n",
      "Topic #2: harry looked\n",
      "Topic #3: neville malfoy\n",
      "Topic #4: ron hermione\n",
      "\n",
      "CPU times: user 5.67 s, sys: 6.31 ms, total: 5.67 s\n",
      "Wall time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "(tf_vectorizer, tf) = get_tf_data(txt)\n",
    "lda = LatentDirichletAllocation(n_components=n_components, \n",
    "                                max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "lda.fit(tf)\n",
    "print_top_words(lda, tf_vectorizer.get_feature_names(), n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('harry', 0.5998025983119938), ('said', 0.3081132992291062), ('hagrid', 0.2109997818116515), ('ron', 0.20964010372737452), ('look', 0.15713284677327347)]\n",
      "CPU times: user 1min 39s, sys: 3.21 s, total: 1min 42s\n",
      "Wall time: 3min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "joined = '. '.join(txt)\n",
    "kwd = keywords.keywords(joined, scores=True,)\n",
    "print(kwd[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
